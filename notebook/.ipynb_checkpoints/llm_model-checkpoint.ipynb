{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-stack\n",
      "  Downloading llama_stack-0.0.56-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blobfile (from llama-stack)\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fire (from llama-stack)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "     ---------------------------------------- 0.0/87.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 87.2/87.2 kB 4.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: httpx in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.24.2)\n",
      "Collecting llama-models>=0.0.56 (from llama-stack)\n",
      "  Downloading llama_models-0.0.56-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting llama-stack-client>=0.0.56 (from llama-stack)\n",
      "  Downloading llama_stack_client-0.0.56-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: prompt-toolkit in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (3.0.47)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (1.0.1)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.32.3)\n",
      "Requirement already satisfied: rich in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (13.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (69.5.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (3.1.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (10.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (3.7.1)\n",
      "Requirement already satisfied: click in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (2.2.2)\n",
      "Collecting pyaml (from llama-stack-client>=0.0.56->llama-stack)\n",
      "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.12.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpcore==1.*->httpx->llama-stack) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pydantic>=2->llama-stack) (2.20.1)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile->llama-stack)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (2.2.2)\n",
      "Requirement already satisfied: lxml>=4.9 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (5.2.2)\n",
      "Requirement already satisfied: filelock>=3.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from huggingface-hub->llama-stack) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from huggingface-hub->llama-stack) (23.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from requests->llama-stack) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from rich->llama-stack) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from rich->llama-stack) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from anyio<5,>=3.5.0->llama-stack-client>=0.0.56->llama-stack) (1.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from tqdm->llama-stack-client>=0.0.56->llama-stack) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from jinja2->llama-models>=0.0.56->llama-stack) (2.1.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from tiktoken->llama-models>=0.0.56->llama-stack) (2024.7.24)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.0.56->llama-stack) (1.16.0)\n",
      "Downloading llama_stack-0.0.56-py3-none-any.whl (390 kB)\n",
      "   ---------------------------------------- 0.0/390.6 kB ? eta -:--:--\n",
      "   --------------------------------------  389.1/390.6 kB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.6/390.6 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading llama_models-0.0.56-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 16.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.6 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.1/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading llama_stack_client-0.0.56-py3-none-any.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/285.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 285.8/285.8 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.4/75.4 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.6/1.8 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.8 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.4/1.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114261 sha256=34f3c35c06eaae6da73ea812f5a10ef6794a6952e5a268fdf7ce2f58913612f5\n",
      "  Stored in directory: c:\\users\\haris\\appdata\\local\\pip\\cache\\wheels\\19\\39\\2f\\2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "Successfully built fire\n",
      "Installing collected packages: pycryptodomex, pyaml, fire, blobfile, llama-stack-client, llama-models, llama-stack\n",
      "Successfully installed blobfile-3.0.0 fire-0.7.0 llama-models-0.0.56 llama-stack-0.0.56 llama-stack-client-0.0.56 pyaml-24.9.0 pycryptodomex-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install llama-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-stack in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (0.0.56)\n",
      "Requirement already satisfied: blobfile in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (3.0.0)\n",
      "Requirement already satisfied: fire in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.24.2)\n",
      "Requirement already satisfied: llama-models>=0.0.56 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.0.56)\n",
      "Requirement already satisfied: llama-stack-client>=0.0.56 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (0.0.56)\n",
      "Requirement already satisfied: prompt-toolkit in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (3.0.47)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (1.0.1)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.32.3)\n",
      "Requirement already satisfied: rich in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (13.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (69.5.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack) (2.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (3.1.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-models>=0.0.56->llama-stack) (10.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (3.7.1)\n",
      "Requirement already satisfied: click in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (8.1.7)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (2.2.2)\n",
      "Requirement already satisfied: pyaml in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (24.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (1.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from llama-stack-client>=0.0.56->llama-stack) (4.12.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpx->llama-stack) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from httpcore==1.*->httpx->llama-stack) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pydantic>=2->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pydantic>=2->llama-stack) (2.20.1)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (3.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (2.2.2)\n",
      "Requirement already satisfied: lxml>=4.9 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (5.2.2)\n",
      "Requirement already satisfied: filelock>=3.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from blobfile->llama-stack) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from huggingface-hub->llama-stack) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from huggingface-hub->llama-stack) (23.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from prompt-toolkit->llama-stack) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from requests->llama-stack) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from rich->llama-stack) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from rich->llama-stack) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from anyio<5,>=3.5.0->llama-stack-client>=0.0.56->llama-stack) (1.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->llama-stack) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from tqdm->llama-stack-client>=0.0.56->llama-stack) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from jinja2->llama-models>=0.0.56->llama-stack) (2.1.5)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from pandas->llama-stack-client>=0.0.56->llama-stack) (2024.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from tiktoken->llama-models>=0.0.56->llama-stack) (2024.7.24)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\haris\\miniconda3\\envs\\env_langchain1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client>=0.0.56->llama-stack) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install llama-stack -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1500980386.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    llama model list\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "llama model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_langchain1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
